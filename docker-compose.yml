version: "3.8"

networks:
  vdt-assignment:
    driver: bridge

services:
  zookeeper:
    image: confluentinc/cp-zookeeper:latest
    container_name: zookeeper
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
    networks:
      - vdt-assignment
    ports:
      - "2181:2181"

  kafka:
    image: confluentinc/cp-kafka:latest
    container_name: kafka
    hostname: kafka
    depends_on:
      - zookeeper
    environment:
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: true
      KAFKA_LISTENERS: PLAINTEXT_HOST://kafka:9092, PLAINTEXT://kafka:29092
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT_HOST://localhost:9092, PLAINTEXT://kafka:29092
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT, PLAINTEXT_HOST:PLAINTEXT,
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
    networks:
      - vdt-assignment
    ports:
      - "9092:9092"

  nifi:
    cap_add:
      - NET_ADMIN # low port bindings
    image: apache/nifi
    container_name: nifi
    environment:
      - SINGLE_USER_CREDENTIALS_USERNAME=admin
      - SINGLE_USER_CREDENTIALS_PASSWORD=admin
      - NIFI_WEB_HTTP_PORT=8888
      - NIFI_WEB_HTTP_HOST=0.0.0.0
    networks:
      - vdt-assignment
    ports:
      - "8888:8888/tcp" # HTTP interface
      - "514:514/tcp" # Syslog
      - "514:514/udp" # Syslog
      - "2055:2055/udp" # NetFlow
    volumes:
      - nifi-conf:/opt/nifi/nifi-current/conf
      - nifi_flowfile:/opt/nifi/nifi-current/flowfile_repository
      - nifi_content:/opt/nifi/nifi-current/content_repository
    restart: unless-stopped

  # Spark cluster

  spark-master:
    image: bitnami/spark:latest
    container_name: spark-master
    hostname: spark-master
    networks:
      - vdt-assignment
    ports:
      - '8080:8080'
      - '7077:7077'
      - '4040:4040'
    environment:
      - SPARK_MODE=master
      - SPARK_MASTER_PORT=7077
      - SPARK_MASTER_WEBUI_PORT=8080
      - SPARK_DAEMON_MEMORY=1G
      - SPARK_RPC_AUTHENTICATION_ENABLED=no
      - SPARK_RPC_ENCRYPTION_ENABLED=no
      - SPARK_LOCAL_STORAGE_ENCRYPTION_ENABLED=no
      - SPARK_SSL_ENABLED=no
      - SPARK_USER=spark
      - SPARK_METRICS_ENABLED=true
    volumes:
      - ./config/config.py:/opt/bitnami/spark/config.py
      - ./spark/processing.py:/opt/bitnami/spark/processing.py
      - spark_master:/bitnami
    deploy:
      resources:
        limits:
          memory: 1024M
    restart: always

  spark-worker-1:
    image: bitnami/spark:latest
    container_name: spark-worker-1
    hostname: spark-worker-1
    networks:
      - vdt-assignment
    depends_on:
      - spark-master
    ports:
      - '18080:8080'
      - '4041:4040'
    environment:
      - SPARK_MODE=worker
      - SPARK_MASTER_URL=spark://spark-master:7077
      - SPARK_WORKER_MEMORY=1G
      - SPARK_WORKER_CORES=2
      - SPARK_WORKER_WEBUI_PORT=4040
      - SPARK_RPC_AUTHENTICATION_ENABLED=no
      - SPARK_RPC_ENCRYPTION_ENABLED=no
      - SPARK_LOCAL_STORAGE_ENCRYPTION_ENABLED=no
      - SPARK_SSL_ENABLED=no
      - SPARK_USER=spark
      - SPARK_METRICS_ENABLED=true
    volumes:
      - ./config/config.py:/opt/bitnami/spark/config.py
      - ./spark/processing.py:/opt/bitnami/spark/processing.py
      - spark_worker_1:/bitnami
    deploy:
      resources:
        limits:
          memory: 1024M
    restart: always

  #Hadoop cluster

  namenode:
    image: bde2020/hadoop-namenode:2.0.0-hadoop3.2.1-java8
    container_name: namenode
    restart: always
    networks:
      - vdt-assignment
    ports:
      - 9870:9870
      - 9000:9000
    volumes:
      - hadoop_namenode:/hadoop/dfs/namenode
    environment:
      - CLUSTER_NAME=test
    env_file:
      - config/hadoop.env

  datanode:
    image: bde2020/hadoop-datanode:2.0.0-hadoop3.2.1-java8
    container_name: datanode
    restart: always
    networks:
      - vdt-assignment
    volumes:
      - hadoop_datanode:/hadoop/dfs/data
    environment:
      SERVICE_PRECONDITION: "namenode:9870"
    env_file:
      - config/hadoop.env

  resourcemanager:
    image: bde2020/hadoop-resourcemanager:2.0.0-hadoop3.2.1-java8
    container_name: resourcemanager
    restart: always
    networks:
      - vdt-assignment
    environment:
      SERVICE_PRECONDITION: "namenode:9000 namenode:9870 datanode:9864"
    env_file:
      - config/hadoop.env

  nodemanager1:
    image: bde2020/hadoop-nodemanager:2.0.0-hadoop3.2.1-java8
    container_name: nodemanager
    restart: always
    networks:
      - vdt-assignment
    environment:
      SERVICE_PRECONDITION: "namenode:9000 namenode:9870 datanode:9864 resourcemanager:8088"
    env_file:
      - config/hadoop.env

  historyserver:
    image: bde2020/hadoop-historyserver:2.0.0-hadoop3.2.1-java8
    container_name: historyserver
    restart: always
    networks:
      - vdt-assignment
    environment:
      SERVICE_PRECONDITION: "namenode:9000 namenode:9870 datanode:9864 resourcemanager:8088"
    volumes:
      - hadoop_historyserver:/hadoop/yarn/timeline
    env_file:
      - config/hadoop.env


volumes:
  spark_master:
  spark_worker_1:
  hadoop_namenode:
  hadoop_datanode:
  hadoop_historyserver:
  nifi-conf:
  nifi_flowfile:
  nifi_content:


